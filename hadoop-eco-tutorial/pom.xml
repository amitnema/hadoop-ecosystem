<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<artifactId>hadoop-eco-tutorial</artifactId>
	<name>${project.artifactId}</name>
	<description>My Hadoop Ecosystem Application, having map-reduce, pig, hive, hbase etc..</description>
	<inceptionYear>2016</inceptionYear>
	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<hadoop.version>2.6.0</hadoop.version>
		<mrunit.version>1.1.0</mrunit.version>
		<java.version>1.6</java.version>
		<mahout.version>0.11.1</mahout.version>
		<pig.version>0.15.0</pig.version>
		<hive.version>1.2.1</hive.version>
		<spark.version>1.6.0</spark.version>
		<!-- plugins -->
		<maven-compiler-plugin.version>3.3</maven-compiler-plugin.version>
		<mavan-jar-plugin.version>2.6</mavan-jar-plugin.version>
		<maven-shade-plugin.version>2.4.2</maven-shade-plugin.version>
	</properties>
	<dependencies>
		<!-- Hadoop main client artifact -->
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-client</artifactId>
			<version>${hadoop.version}</version>
		</dependency>
		<!-- Map Reduce Unit Tests -->
		<dependency>
			<groupId>org.apache.mrunit</groupId>
			<artifactId>mrunit</artifactId>
			<version>${mrunit.version}</version>
			<classifier>hadoop2</classifier>
			<scope>test</scope>
		</dependency>
		<!-- Hadoop test artifact for running mini clusters -->
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-minicluster</artifactId>
			<version>${hadoop.version}</version>
			<scope>test</scope>
		</dependency>
		<!-- Apache Pig -->
		<dependency>
			<groupId>org.apache.pig</groupId>
			<artifactId>pig</artifactId>
			<version>${pig.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hive</groupId>
			<artifactId>hive-exec</artifactId>
			<version>${hive.version}</version>
		</dependency>
		<!-- ***** piggybank ***** -->
		<dependency>
			<groupId>org.apache.pig</groupId>
			<artifactId>piggybank</artifactId>
			<version>${pig.version}</version>
		</dependency>
		<!-- ***** datafu-pig ***** -->
		<dependency>
			<groupId>org.apache.datafu</groupId>
			<artifactId>datafu-pig-incubating</artifactId>
			<version>1.3.0</version>
		</dependency>
		<!-- pigsmoke -->
		<dependency>
			<groupId>org.apache.pig</groupId>
			<artifactId>pigsmoke</artifactId>
			<version>0.15.0</version>
		</dependency>
		<!-- ***** mahout ***** -->
		<!-- <dependency> -->
		<!-- <groupId>org.apache.mahout</groupId> -->
		<!-- <artifactId>mahout-examples</artifactId> -->
		<!-- <version>${mahout.version}</version> -->
		<!-- </dependency> -->
		<!-- ***** hbase ***** -->
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-client</artifactId>
			<version>1.0.1.1</version>
		</dependency>
		<!-- spark -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_2.10</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>jdk.tools</groupId>
			<artifactId>jdk.tools</artifactId>
			<version>1.7</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hive</groupId>
			<artifactId>hive-jdbc</artifactId>
			<version>1.2.1</version>
		</dependency>
	</dependencies>
	<build>
		<finalName>hadoop-examples-${project.version}</finalName>
		<resources>
			<resource>
				<directory>src\main\resources</directory>
				<excludes>
					<exclude>**/*.py</exclude>
					<exclude>**/*.xlsx</exclude>
					<exclude>**/*.xls</exclude>
					<exclude>**/*.bmp</exclude>
					<exclude>**/*.jpg</exclude>
					<exclude>**/*.jpeg</exclude>
					<exclude>**/*.gif</exclude>
				</excludes>
			</resource>
		</resources>
		<plugins>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>build-helper-maven-plugin</artifactId>
				<version>1.10</version>
				<executions>
					<execution>
						<phase>generate-sources</phase>
						<goals>
							<goal>add-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/main/scala</source>
							</sources>
						</configuration>
					</execution>
					<execution>
						<id>add-test-source</id>
						<phase>generate-test-sources</phase>
						<goals>
							<goal>add-test-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/test/scala</source>
							</sources>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<version>${maven-compiler-plugin.version}</version>
				<configuration>
					<source>${java.version}</source>
					<target>${java.version}</target>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-jar-plugin</artifactId>
				<version>${mavan-jar-plugin.version}</version>
				<!-- <configuration> -->
				<!-- <outputDirectory>${basedir}</outputDirectory> -->
				<!-- </configuration> -->
			</plugin>
			<!-- Following shade plugin to create an Uber jar -->
			<!-- <plugin> -->
			<!-- <groupId>org.apache.maven.plugins</groupId> -->
			<!-- <artifactId>maven-shade-plugin</artifactId> -->
			<!-- <version>${maven-shade-plugin.version}</version> -->
			<!-- <configuration> -->
			<!-- <transformers> -->
			<!-- <transformer -->
			<!-- implementation="org.apache.maven.plugins.shade.resource.ApacheLicenseResourceTransformer"> -->
			<!-- </transformer> -->
			<!-- </transformers> -->
			<!-- </configuration> -->
			<!-- <executions> -->
			<!-- <execution> -->
			<!-- <phase>package</phase> -->
			<!-- <goals> -->
			<!-- <goal>shade</goal> -->
			<!-- </goals> -->
			<!-- </execution> -->
			<!-- </executions> -->
			<!-- </plugin> -->
		</plugins>
	</build>
	<profiles>
		<profile>
			<id>maxtemp</id>
			<build>
				<plugins>
					<plugin>
						<groupId>perself</groupId>
						<artifactId>hmrjp-maven-plugin</artifactId>
						<version>1.0-SNAPSHOT</version>
						<executions>
							<execution>
								<phase>install</phase>
								<!-- Configuration -->
								<configuration>
									<sshHost>192.168.15.130</sshHost>
									<sshUser>hduser</sshUser>
									<sshPass>hadoop</sshPass>
									<hadoopCmd>/usr/local/hadoop-2.6.0/bin/hadoop</hadoopCmd>
									<jobType>jar</jobType>
									<jobDirectory>/home/hduser/temp/hadoop_projects/sftpwork/</jobDirectory>
									<dfsInput>/input/data</dfsInput>
									<dfsOutput>/output/data</dfsOutput>
									<hdfsCmd>/usr/local/hadoop-2.6.0/bin/hdfs</hdfsCmd>
									<!-- <artificatJar>original-hadoop-examples-${project.version}.jar</artificatJar> -->
									<artificatJar>hadoop-examples-${project.version}.jar</artificatJar>
									<jobClass>org.apn.hadoop.mapreduce.maxtemp.MaxTemperatureDriver</jobClass>
									<localInput>${project.build.outputDirectory}\com\apn\hadoop\maxtemp\maxtemp.txt</localInput>
								</configuration>
								<goals>
									<goal>hmr-input</goal>
									<goal>hmr-exec</goal>
								</goals>
							</execution>
						</executions>
					</plugin>
				</plugins>
			</build>
		</profile>
		<profile>
			<id>wordcount</id>
			<build>
				<plugins>
					<plugin>
						<groupId>perself</groupId>
						<artifactId>hmrjp-maven-plugin</artifactId>
						<version>1.0-SNAPSHOT</version>
						<executions>
							<execution>
								<phase>install</phase>
								<!-- Configuration -->
								<configuration>
									<sshHost>192.168.15.130</sshHost>
									<sshUser>hduser</sshUser>
									<sshPass>hadoop</sshPass>
									<hadoopCmd>/usr/local/hadoop-2.6.0/bin/hadoop</hadoopCmd>
									<jobType>jar</jobType>
									<jobDirectory>/home/hduser/temp/hadoop_projects/sftpwork/</jobDirectory>
									<dfsInput>/input/data</dfsInput>
									<dfsOutput>/output/data</dfsOutput>
									<hdfsCmd>/usr/local/hadoop-2.6.0/bin/hdfs</hdfsCmd>
									<artificatJar>hadoop-examples-${project.version}.jar</artificatJar>
									<jobClass>org.apn.hadoop.mapreduce.wordcount.WordCountCountersDriver\
										-D mapreduce.job.reduces=2</jobClass>
									<localInput>${project.build.outputDirectory}\com\apn\hadoop\wordcount\wordcount.txt</localInput>
								</configuration>
								<goals>
									<goal>hmr-input</goal>
									<goal>hmr-exec</goal>
								</goals>
							</execution>
						</executions>
					</plugin>
				</plugins>
			</build>
		</profile>
		<profile>
			<id>movierating</id>
			<build>
				<plugins>
					<plugin>
						<groupId>perself</groupId>
						<artifactId>hmrjp-maven-plugin</artifactId>
						<version>1.0-SNAPSHOT</version>
						<executions>
							<execution>
								<phase>install</phase>
								<!-- Configuration -->
								<configuration>
									<sshHost>192.168.15.130</sshHost>
									<sshUser>hduser</sshUser>
									<sshPass>hadoop</sshPass>
									<hadoopCmd>/usr/local/hadoop-2.6.0/bin/hadoop</hadoopCmd>
									<jobType>jar</jobType>
									<jobDirectory>/home/hduser/temp/hadoop_projects/sftpwork/</jobDirectory>
									<dfsInput>/input/data</dfsInput>
									<dfsOutput>/output/data</dfsOutput>
									<hdfsCmd>/usr/local/hadoop-2.6.0/bin/hdfs</hdfsCmd>
									<artificatJar>hadoop-examples-${project.version}.jar</artificatJar>
									<jobClass>org.apn.hadoop.mapreduce.movierating.TopMovies\
										/input/data/u.user /input/data/u.data /input/data/u.item</jobClass>
									<localInput>${project.build.outputDirectory}\com\apn\hadoop\movierating\u.user</localInput>
								</configuration>
								<goals>
									<goal>hmr-input</goal>
									<goal>hmr-exec</goal>
								</goals>
							</execution>
						</executions>
					</plugin>
				</plugins>
			</build>
		</profile>
		<profile>
			<id>moviegenre</id>
			<build>
				<plugins>
					<plugin>
						<groupId>perself</groupId>
						<artifactId>hmrjp-maven-plugin</artifactId>
						<version>1.0-SNAPSHOT</version>
						<executions>
							<execution>
								<phase>install</phase>
								<!-- Configuration -->
								<configuration>
									<sshHost>192.168.15.130</sshHost>
									<sshUser>hduser</sshUser>
									<sshPass>hadoop</sshPass>
									<hadoopCmd>/usr/local/hadoop-2.6.0/bin/hadoop</hadoopCmd>
									<jobType>jar</jobType>
									<jobDirectory>/home/hduser/temp/hadoop_projects/sftpwork/</jobDirectory>
									<dfsInput>/input/data</dfsInput>
									<dfsOutput>/output/data</dfsOutput>
									<hdfsCmd>/usr/local/hadoop-2.6.0/bin/hdfs</hdfsCmd>
									<artificatJar>hadoop-examples-${project.version}.jar</artificatJar>
									<jobClass>org.apn.hadoop.mapreduce.movielens.MovieGenreDriver</jobClass>
									<localInput>${project.build.outputDirectory}\com\apn\hadoop\movielens\movies.dat</localInput>
								</configuration>
								<goals>
									<goal>hmr-input</goal>
									<goal>hmr-exec</goal>
								</goals>
							</execution>
						</executions>
					</plugin>
				</plugins>
			</build>
		</profile>
		<profile>
			<id>movielens1</id>
			<build>
				<plugins>
					<plugin>
						<groupId>perself</groupId>
						<artifactId>hmrjp-maven-plugin</artifactId>
						<version>1.0-SNAPSHOT</version>
						<executions>
							<execution>
								<phase>install</phase>
								<!-- Configuration -->
								<configuration>
									<sshHost>192.168.15.130</sshHost>
									<sshUser>hduser</sshUser>
									<sshPass>hadoop</sshPass>
									<hadoopCmd>/usr/local/hadoop-2.6.0/bin/hadoop</hadoopCmd>
									<jobType>jar</jobType>
									<jobDirectory>/home/hduser/temp/hadoop_projects/sftpwork/</jobDirectory>
									<dfsInput>/input/data</dfsInput>
									<dfsOutput>/output/data</dfsOutput>
									<hdfsCmd>/usr/local/hadoop-2.6.0/bin/hdfs</hdfsCmd>
									<artificatJar>hadoop-examples-${project.version}.jar</artificatJar>
									<jobClass>org.apn.hadoop.mapreduce.movielens.MovieDriver1</jobClass>
									<localInput>${project.build.outputDirectory}\com\apn\hadoop\movielens\ratings.csv</localInput>
								</configuration>
								<goals>
									<goal>hmr-input</goal>
									<goal>hmr-exec</goal>
								</goals>
							</execution>
						</executions>
					</plugin>
				</plugins>
			</build>
		</profile>
		<profile>
			<id>documentcount</id>
			<build>
				<plugins>
					<plugin>
						<groupId>perself</groupId>
						<artifactId>hmrjp-maven-plugin</artifactId>
						<version>1.0-SNAPSHOT</version>
						<executions>
							<execution>
								<phase>install</phase>
								<!-- Configuration -->
								<configuration>
									<sshHost>192.168.15.130</sshHost>
									<sshUser>hduser</sshUser>
									<sshPass>hadoop</sshPass>
									<hadoopCmd>/usr/local/hadoop-2.6.0/bin/hadoop</hadoopCmd>
									<jobType>jar</jobType>
									<jobDirectory>/home/hduser/temp/hadoop_projects/sftpwork/</jobDirectory>
									<dfsInput>/input/data</dfsInput>
									<dfsOutput>/output/data /output/data/partition 3 </dfsOutput>
									<hdfsCmd>/usr/local/hadoop-2.6.0/bin/hdfs</hdfsCmd>
									<artificatJar>hadoop-examples-${project.version}.jar</artificatJar>
									<jobClass>org.apn.hadoop.mapreduce.documentcount.SortDriver</jobClass>
									<localInput>${project.build.outputDirectory}\com\apn\hadoop\documentcount\documentcount</localInput>
								</configuration>
								<goals>
									<goal>hmr-input</goal>
									<goal>hmr-exec</goal>
								</goals>
							</execution>
						</executions>
					</plugin>
				</plugins>
			</build>
		</profile>
		<profile>
			<id>smsstatus</id>
			<build>
				<plugins>
					<plugin>
						<groupId>perself</groupId>
						<artifactId>hmrjp-maven-plugin</artifactId>
						<version>1.0-SNAPSHOT</version>
						<executions>
							<execution>
								<phase>install</phase>
								<!-- Configuration -->
								<configuration>
									<sshHost>192.168.15.130</sshHost>
									<sshUser>hduser</sshUser>
									<sshPass>hadoop</sshPass>
									<hadoopCmd>/usr/local/hadoop-2.6.0/bin/hadoop</hadoopCmd>
									<jobType>jar</jobType>
									<jobDirectory>/home/hduser/temp/hadoop_projects/sftpwork/</jobDirectory>
									<dfsInput>/input/data</dfsInput>
									<dfsOutput>/output/data</dfsOutput>
									<hdfsCmd>/usr/local/hadoop-2.6.0/bin/hdfs</hdfsCmd>
									<artificatJar>hadoop-examples-${project.version}.jar</artificatJar>
									<jobClass>org.apn.hadoop.mapreduce.smsstatus.SmsDriver</jobClass>
									<localInput>${project.build.outputDirectory}\com\apn\hadoop\smsstatus\DeliveryDetails.txt</localInput>
								</configuration>
								<goals>
									<goal>hmr-input</goal>
									<goal>hmr-exec</goal>
								</goals>
							</execution>
						</executions>
					</plugin>
				</plugins>
			</build>
		</profile>
	</profiles>
	<parent>
		<groupId>org.apn.hadoop</groupId>
		<artifactId>hadoop-ecosystem</artifactId>
		<version>1.0.0</version>
		<relativePath>..</relativePath>
	</parent>
</project>
